{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0c755cb-e0dc-406a-8031-dc7e2a24b55e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test: 350701 87181\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "mlflow.set_experiment(\"/Shared/air_quality_forecasting\")\n",
    "\n",
    "df = spark.table(\"workspace.air_quality.silver_air_quality\")\n",
    "\n",
    "base = (df\n",
    "  .filter(F.col(\"pm25_ugm3\").isNotNull() & (~F.isnan(\"pm25_ugm3\")))\n",
    "  .filter(F.col(\"pm25_ugm3\") > 0)\n",
    "  .filter(F.col(\"date\").isNotNull() & F.col(\"city_code\").isNotNull())\n",
    ")\n",
    "\n",
    "w = Window.partitionBy(\"city_code\").orderBy(\"date\")\n",
    "\n",
    "ml_df = (base\n",
    "  .withColumn(\"day_of_week\", F.dayofweek(\"date\").cast(\"double\"))\n",
    "  .withColumn(\"month\", F.month(\"date\").cast(\"double\"))\n",
    "  .withColumn(\"pm25_lag1\", F.lag(\"pm25_ugm3\", 1).over(w))\n",
    "  .filter(F.col(\"pm25_lag1\").isNotNull())\n",
    "  .select(\n",
    "      \"pm25_ugm3\",                       \n",
    "      \"pm25_lag1\", \"temp_c\", \"relative_humidity_pct\", \"wind_speed_ms\",\n",
    "      \"day_of_week\", \"month\"\n",
    "  )\n",
    ")\n",
    "\n",
    "train_df, test_df = ml_df.randomSplit([0.8, 0.2], seed=42)\n",
    "print(\"Train/Test:\", train_df.count(), test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96e0bf22-5911-49e4-a285-343a87218c2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>database</th><th>volume_name</th></tr></thead><tbody><tr><td>air_quality</td><td>data</td></tr><tr><td>air_quality</td><td>mlflow_artifacts</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "air_quality",
         "data"
        ],
        [
         "air_quality",
         "mlflow_artifacts"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "database",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "volume_name",
            "nullable": false,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 3
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "database",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "volume_name",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "CREATE VOLUME IF NOT EXISTS workspace.air_quality.mlflow_artifacts;\n",
    "\n",
    "SHOW VOLUMES IN workspace.air_quality;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d986b2b-d526-4b1a-83aa-4487104e7c77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD27 CLEANING: Filter PM2.5 > 2 µg/m³ (remove sensor noise)\n✅ Clean dataset: Train 348,472 | Test 86,641 rows\n\uD83D\uDE80 Training serverless model...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/01 17:38:58 WARNING mlflow.utils.requirements_utils: Found pyspark version (4.0.0+databricks.connect.17.2.2) contains a local version label (+databricks.connect.17.2.2). MLflow logged a pip requirement for this package as 'pyspark==4.0.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n2026/02/01 17:39:02 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /local_disk0/user_tmp_data/spark-8cc0b864-7501-4e09-a67d-9f/tmpphn469w0/model, flavor: spark). Fall back to return ['pyspark==4.0.0']. Set logging level to DEBUG to see the full traceback. \nSuccessfully registered model 'workspace.air_quality.pm25_forecast_serverless_fixed_v1'.\nCreated version '1' of model 'workspace.air_quality.pm25_forecast_serverless_fixed_v1'.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\uD83C\uDFAF PRODUCTION METRICS (PM2.5 > 2 µg/m³):\n   Log RMSE:     0.536\n   PM2.5 RMSE:   56.4 µg/m³\n   PM2.5 MAE:    28.4 µg/m³\n   PM2.5 MAPE:   49.6%\n   R² (log):     0.682\n✅ SERVERLESS MODEL REGISTERED!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>actual_pm25</th><th>predicted_pm25</th><th>abs_error</th><th>mape_%</th><th>aqi_category</th></tr></thead><tbody><tr><td>2.03</td><td>11.1</td><td>9.0</td><td>445.4</td><td>GOOD</td></tr><tr><td>2.04</td><td>9.3</td><td>7.3</td><td>357.1</td><td>GOOD</td></tr><tr><td>2.04</td><td>26.3</td><td>24.3</td><td>1190.6</td><td>GOOD</td></tr><tr><td>2.04</td><td>9.1</td><td>7.1</td><td>346.3</td><td>GOOD</td></tr><tr><td>2.04</td><td>11.4</td><td>9.4</td><td>459.0</td><td>GOOD</td></tr><tr><td>2.04</td><td>10.9</td><td>8.9</td><td>436.0</td><td>GOOD</td></tr><tr><td>2.04</td><td>8.2</td><td>6.1</td><td>301.0</td><td>GOOD</td></tr><tr><td>2.04</td><td>13.8</td><td>11.7</td><td>575.5</td><td>GOOD</td></tr><tr><td>2.05</td><td>9.3</td><td>7.3</td><td>355.7</td><td>GOOD</td></tr><tr><td>2.06</td><td>9.2</td><td>7.1</td><td>344.8</td><td>GOOD</td></tr><tr><td>2.06</td><td>11.1</td><td>9.1</td><td>440.2</td><td>GOOD</td></tr><tr><td>2.06</td><td>10.8</td><td>8.7</td><td>424.7</td><td>GOOD</td></tr><tr><td>2.07</td><td>40.8</td><td>38.7</td><td>1868.8</td><td>GOOD</td></tr><tr><td>2.07</td><td>17.5</td><td>15.4</td><td>744.0</td><td>GOOD</td></tr><tr><td>2.08</td><td>9.1</td><td>7.0</td><td>337.7</td><td>GOOD</td></tr><tr><td>2.09</td><td>22.9</td><td>20.8</td><td>993.7</td><td>GOOD</td></tr><tr><td>2.09</td><td>9.6</td><td>7.5</td><td>358.4</td><td>GOOD</td></tr><tr><td>2.09</td><td>39.6</td><td>37.5</td><td>1792.8</td><td>GOOD</td></tr><tr><td>2.1</td><td>9.3</td><td>7.2</td><td>341.1</td><td>GOOD</td></tr><tr><td>2.1</td><td>12.3</td><td>10.2</td><td>484.0</td><td>GOOD</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         2.03,
         11.1,
         9.0,
         445.4,
         "GOOD"
        ],
        [
         2.04,
         9.3,
         7.3,
         357.1,
         "GOOD"
        ],
        [
         2.04,
         26.3,
         24.3,
         1190.6,
         "GOOD"
        ],
        [
         2.04,
         9.1,
         7.1,
         346.3,
         "GOOD"
        ],
        [
         2.04,
         11.4,
         9.4,
         459.0,
         "GOOD"
        ],
        [
         2.04,
         10.9,
         8.9,
         436.0,
         "GOOD"
        ],
        [
         2.04,
         8.2,
         6.1,
         301.0,
         "GOOD"
        ],
        [
         2.04,
         13.8,
         11.7,
         575.5,
         "GOOD"
        ],
        [
         2.05,
         9.3,
         7.3,
         355.7,
         "GOOD"
        ],
        [
         2.06,
         9.2,
         7.1,
         344.8,
         "GOOD"
        ],
        [
         2.06,
         11.1,
         9.1,
         440.2,
         "GOOD"
        ],
        [
         2.06,
         10.8,
         8.7,
         424.7,
         "GOOD"
        ],
        [
         2.07,
         40.8,
         38.7,
         1868.8,
         "GOOD"
        ],
        [
         2.07,
         17.5,
         15.4,
         744.0,
         "GOOD"
        ],
        [
         2.08,
         9.1,
         7.0,
         337.7,
         "GOOD"
        ],
        [
         2.09,
         22.9,
         20.8,
         993.7,
         "GOOD"
        ],
        [
         2.09,
         9.6,
         7.5,
         358.4,
         "GOOD"
        ],
        [
         2.09,
         39.6,
         37.5,
         1792.8,
         "GOOD"
        ],
        [
         2.1,
         9.3,
         7.2,
         341.1,
         "GOOD"
        ],
        [
         2.1,
         12.3,
         10.2,
         484.0,
         "GOOD"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "actual_pm25",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "predicted_pm25",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "abs_error",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "mape_%",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "aqi_category",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.feature import Imputer, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import functions as F\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Serverless compute environment variables\n",
    "os.environ['SPARKML_TEMP_DFS_PATH'] = '/Volumes/workspace/air_quality/mlflow_artifacts/tmp'\n",
    "os.environ['MLFLOW_DFS_TMP'] = '/Volumes/workspace/air_quality/mlflow_artifacts/tmp'\n",
    "\n",
    "feature_cols = [\"pm25_lag1\", \"temp_c\", \"relative_humidity_pct\", \"wind_speed_ms\", \"day_of_week\", \"month\"]\n",
    "\n",
    "print(\"\uD83D\uDD27 CLEANING: Filter PM2.5 > 2 µg/m³ (remove sensor noise)\")\n",
    "train_df_clean = (train_df\n",
    "                  .filter(F.col(\"pm25_ugm3\") > 2.0)\n",
    "                  .withColumn(\"pm25_log\", F.log1p(F.col(\"pm25_ugm3\"))))\n",
    "\n",
    "test_df_clean = (test_df\n",
    "                 .filter(F.col(\"pm25_ugm3\") > 2.0)\n",
    "                 .withColumn(\"pm25_log\", F.log1p(F.col(\"pm25_ugm3\"))))\n",
    "\n",
    "print(f\"✅ Clean dataset: Train {train_df_clean.count():,} | Test {test_df_clean.count():,} rows\")\n",
    "\n",
    "# Production pipeline\n",
    "imputer = Imputer(inputCols=feature_cols, outputCols=[c + \"_imp\" for c in feature_cols]).setStrategy(\"median\")\n",
    "assembler = VectorAssembler(inputCols=[c + \"_imp\" for c in feature_cols], outputCol=\"features\", handleInvalid=\"skip\")\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"features_scaled\", withStd=True, withMean=True)\n",
    "\n",
    "gbt = GBTRegressor(\n",
    "    featuresCol=\"features_scaled\", \n",
    "    labelCol=\"pm25_log\",\n",
    "    maxIter=20,\n",
    "    maxDepth=4, \n",
    "    stepSize=0.2,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=[imputer, assembler, scaler, gbt])\n",
    "\n",
    "# Signature\n",
    "sample_input = spark.createDataFrame([(45.2, 28.5, 65.0, 2.1, 3.0, 2.0)], feature_cols).toPandas()\n",
    "sample_output = pd.DataFrame({\"prediction\": [3.88]})\n",
    "signature = infer_signature(sample_input, sample_output)\n",
    "\n",
    "print(\"\uD83D\uDE80 Training serverless model...\")\n",
    "\n",
    "# Train & register\n",
    "with mlflow.start_run(run_name=\"pm25_serverless_fixed_v1\"):\n",
    "    model = pipeline.fit(train_df_clean)\n",
    "    \n",
    "    pred_log = model.transform(test_df_clean)\n",
    "    \n",
    "    # Log-scale metrics\n",
    "    log_metrics = {}\n",
    "    for metric in [\"rmse\", \"mae\", \"r2\"]:\n",
    "        score = RegressionEvaluator(labelCol=\"pm25_log\", predictionCol=\"prediction\", metricName=metric).evaluate(pred_log)\n",
    "        mlflow.log_metric(f\"log_{metric}\", score)\n",
    "        log_metrics[metric] = score\n",
    "    \n",
    "    # Original scale metrics - FIXED Column callable errors\n",
    "    pred_orig = pred_log.withColumn(\"pred_pm25\", F.exp(pred_log[\"prediction\"]) - 1)\n",
    "    \n",
    "    rmse_orig = RegressionEvaluator(labelCol=\"pm25_ugm3\", predictionCol=\"pred_pm25\", metricName=\"rmse\").evaluate(pred_orig)\n",
    "    mae_orig = RegressionEvaluator(labelCol=\"pm25_ugm3\", predictionCol=\"pred_pm25\", metricName=\"mae\").evaluate(pred_orig)\n",
    "    \n",
    "    # FIXED: Safe MAPE calculation using expr\n",
    "    mape_orig = pred_orig.agg(\n",
    "        F.expr(\"avg(abs((pm25_ugm3 - pred_pm25)/(pm25_ugm3 + 0.1))) * 100\")\n",
    "    ).collect()[0][0]\n",
    "    \n",
    "    mlflow.log_metric(\"rmse_pm25\", rmse_orig)\n",
    "    mlflow.log_metric(\"mae_pm25\", mae_orig)\n",
    "    mlflow.log_metric(\"mape_pm25\", mape_orig)\n",
    "    \n",
    "    # Register model\n",
    "    mlflow.spark.log_model(\n",
    "        model, \n",
    "        \"pm25_serverless_fixed\",\n",
    "        signature=signature,\n",
    "        input_example=sample_input,\n",
    "        registered_model_name=\"workspace.air_quality.pm25_forecast_serverless_fixed_v1\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n\uD83C\uDFAF PRODUCTION METRICS (PM2.5 > 2 µg/m³):\")\n",
    "    print(f\"   Log RMSE:     {log_metrics['rmse']:.3f}\")\n",
    "    print(f\"   PM2.5 RMSE:   {rmse_orig:.1f} µg/m³\")\n",
    "    print(f\"   PM2.5 MAE:    {mae_orig:.1f} µg/m³\")\n",
    "    print(f\"   PM2.5 MAPE:   {mape_orig:.1f}%\")\n",
    "    print(f\"   R² (log):     {log_metrics['r2']:.3f}\")\n",
    "    print(\"✅ SERVERLESS MODEL REGISTERED!\")\n",
    "    \n",
    "    # FIXED: Safe display (no callable column errors)\n",
    "    display(pred_orig\n",
    "        .select(\n",
    "            F.col(\"pm25_ugm3\").alias(\"actual_pm25\"),\n",
    "            F.round(F.col(\"pred_pm25\"), 1).alias(\"predicted_pm25\"),\n",
    "            F.round(F.abs(F.col(\"pm25_ugm3\") - F.col(\"pred_pm25\")), 1).alias(\"abs_error\"),\n",
    "            F.round(\n",
    "                F.when(F.col(\"pm25_ugm3\") > 1, \n",
    "                       (F.abs(F.col(\"pm25_ugm3\") - F.col(\"pred_pm25\")) / F.col(\"pm25_ugm3\")) * 100)\n",
    "                .otherwise(None), 1\n",
    "            ).alias(\"mape_%\"),\n",
    "            F.when(F.col(\"pm25_ugm3\") > 100, F.lit(\"POOR\"))\n",
    "             .when(F.col(\"pm25_ugm3\") > 50, F.lit(\"MODERATE\"))\n",
    "             .otherwise(F.lit(\"GOOD\")).alias(\"aqi_category\")\n",
    "        )\n",
    "        .filter(F.col(\"pm25_ugm3\").between(2, 150))\n",
    "        .orderBy(\"actual_pm25\")\n",
    "        .limit(20))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7436098435201920,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "project4",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}